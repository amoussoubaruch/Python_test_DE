# Python_test_DEThis is my python project for DE test. ###### Part 1 : DataPipeline for drug mentionned in journalYou have too possibility to run this code 1. In local or in server run this command ```python python3 main.py```2. Use Makefile ```shmake rundatapiline make clean```Note : I create in dag directory a simple python code dag for running this pipeline on airflow. ###### Part 2 : Analysis for journal that contains the most drugs's namesI create a simple python code to that in src/fisrt_journal directory. If each day such KPI are asking, we can create a simple api for that. Another application can just make a call to this api to get all kpi they want. For run this part, you can ```python python3 api/main_api.py```or ```shmake runapi make clean```###### Part 3 : Test```shpytest```###### Part 5 : Scaling to 1ToFor scaling the DataPipeline for mentionned drugs, we can in GCP use google storage to store big file csv and change our code in pyspark or scala spark to run it on dataproc. Another good way is to transform python code in apache beam and run the pipeline in dataflow. And instead of storage the output final in json we can use bigquery to perform all analysis we can make later. For api we can use Cloud Function to create a fast api to get information. ###### Part 5 : SQL You can find sql query in sql directory. You have request.sql file that contain all query. Thanks I hope you will like my project structure and what i do. 